{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee139176",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\11151\\Desktop\\learn_py\\.venv\\Lib\\site-packages\\huggingface_hub\\_login.py:334\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\11151\\Desktop\\learn_py\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\11151\\Desktop\\learn_py\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:31\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     33\u001b[39m args_msg = [\n\u001b[32m     34\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     36\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\11151\\Desktop\\learn_py\\.venv\\Lib\\site-packages\\huggingface_hub\\_login.py:337\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m     )\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m get_token() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mUser is already logged in.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6389a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98fe470a674eabbb229855b1824c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11151\\miniconda3\\envs\\myenv3.11\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\11151\\.cache\\huggingface\\hub\\datasets--dany0407--eli5_category. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b1a1a0717142b29b330953ce7bec46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/98.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71ba5951c184a9f8b475ec5e88beede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation1-00000-of-00001.parquet:   0%|          | 0.00/7.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329b3c53cb964e0aa59853449251de6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation2-00000-of-00001.parquet:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b778b95bcb4493a9e0093f165feadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/6.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faa69c3695444f39b0c813fbc2c7343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/91772 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d8f95c36ef44c48ca6d7b9aabf99ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation1 split:   0%|          | 0/5446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d3f7ea3108494ca4b2daa772298909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation2 split:   0%|          | 0/2375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeb79ba477c429997b331312e0f8013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eli5 = load_dataset(\"dany0407/eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064e625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '5lserf',\n",
       " 'title': 'What does the Office of Congressional Ethics do?',\n",
       " 'selftext': 'What are some examples of their contributions/work?',\n",
       " 'category': 'Other',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dby2w54', 'dbye0dg'],\n",
       "  'text': ['The Office of Congressional Ethics is the independent body created in 2008 to investigate allegations of misconduct by lawmakers after several bribery and corruption scandals sent members to prison. Apparently the crooks have decided the best way to stay out of jail is to fire the police department (or at least take away their powers). URL_0',\n",
       "   \"The OCE was supposed to be independent. While that may be true they overstepped their bounds and often leaked allegations (which were made anonymously) even before any conclusions were reached. This had some dire consequences for many innocent people. Spurious accusations could be made without any substantiation and these were sometimes leaked. Congress has decided to back to investigating allegations themselves, which is what they did prior to 2008. The difference now is that the Ethics Committee will receive allegations directly and not anonymously. It's important to note that the committee consists of members of both parties and many Democrats are in favor of dissolving the OCE because their members were harmed just as often.\"],\n",
       "  'score': [7, 6],\n",
       "  'text_urls': [['http://www.tampabay.com/news/politics/house-gop-votes-to-gut-independent-ethics-office/2308207'],\n",
       "   []]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8538cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '5lserf',\n",
       " 'title': 'What does the Office of Congressional Ethics do?',\n",
       " 'selftext': 'What are some examples of their contributions/work?',\n",
       " 'category': 'Other',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers.a_id': ['dby2w54', 'dbye0dg'],\n",
       " 'answers.text': ['The Office of Congressional Ethics is the independent body created in 2008 to investigate allegations of misconduct by lawmakers after several bribery and corruption scandals sent members to prison. Apparently the crooks have decided the best way to stay out of jail is to fire the police department (or at least take away their powers). URL_0',\n",
       "  \"The OCE was supposed to be independent. While that may be true they overstepped their bounds and often leaked allegations (which were made anonymously) even before any conclusions were reached. This had some dire consequences for many innocent people. Spurious accusations could be made without any substantiation and these were sometimes leaked. Congress has decided to back to investigating allegations themselves, which is what they did prior to 2008. The difference now is that the Ethics Committee will receive allegations directly and not anonymously. It's important to note that the committee consists of members of both parties and many Democrats are in favor of dissolving the OCE because their members were harmed just as often.\"],\n",
       " 'answers.score': [7, 6],\n",
       " 'answers.text_urls': [['http://www.tampabay.com/news/politics/house-gop-votes-to-gut-independent-ethics-office/2308207'],\n",
       "  []],\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "eli5 = eli5.flatten()\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d414d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8a4e5e14f34dccb6c4e6f167fa566f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0490fe815843d7b3d8b5ebfa7af31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples, tokenizer):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])\n",
    "\n",
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a65e6210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [464,\n",
       "  4452,\n",
       "  286,\n",
       "  15757,\n",
       "  25092,\n",
       "  318,\n",
       "  262,\n",
       "  4795,\n",
       "  1767,\n",
       "  2727,\n",
       "  287,\n",
       "  3648,\n",
       "  284,\n",
       "  9161,\n",
       "  7636,\n",
       "  286,\n",
       "  17063,\n",
       "  416,\n",
       "  10191,\n",
       "  706,\n",
       "  1811,\n",
       "  37388,\n",
       "  290,\n",
       "  9253,\n",
       "  28449,\n",
       "  1908,\n",
       "  1866,\n",
       "  284,\n",
       "  3770,\n",
       "  13,\n",
       "  18626,\n",
       "  262,\n",
       "  6763,\n",
       "  28194,\n",
       "  423,\n",
       "  3066,\n",
       "  262,\n",
       "  1266,\n",
       "  835,\n",
       "  284,\n",
       "  2652,\n",
       "  503,\n",
       "  286,\n",
       "  7356,\n",
       "  318,\n",
       "  284,\n",
       "  2046,\n",
       "  262,\n",
       "  1644,\n",
       "  5011,\n",
       "  357,\n",
       "  273,\n",
       "  379,\n",
       "  1551,\n",
       "  1011,\n",
       "  1497,\n",
       "  511,\n",
       "  5635,\n",
       "  737,\n",
       "  10289,\n",
       "  62,\n",
       "  15,\n",
       "  383,\n",
       "  440,\n",
       "  5222,\n",
       "  373,\n",
       "  4385,\n",
       "  284,\n",
       "  307,\n",
       "  4795,\n",
       "  13,\n",
       "  2893,\n",
       "  326,\n",
       "  743,\n",
       "  307,\n",
       "  2081,\n",
       "  484,\n",
       "  625,\n",
       "  4169,\n",
       "  1496,\n",
       "  511,\n",
       "  22303,\n",
       "  290,\n",
       "  1690,\n",
       "  14109,\n",
       "  7636,\n",
       "  357,\n",
       "  4758,\n",
       "  547,\n",
       "  925,\n",
       "  35373,\n",
       "  8,\n",
       "  772,\n",
       "  878,\n",
       "  597,\n",
       "  13242,\n",
       "  547,\n",
       "  4251,\n",
       "  13,\n",
       "  770,\n",
       "  550,\n",
       "  617,\n",
       "  19958,\n",
       "  6948,\n",
       "  329,\n",
       "  867,\n",
       "  10218,\n",
       "  661,\n",
       "  13,\n",
       "  1338,\n",
       "  16421,\n",
       "  14227,\n",
       "  714,\n",
       "  307,\n",
       "  925,\n",
       "  1231,\n",
       "  597,\n",
       "  5925,\n",
       "  3920,\n",
       "  290,\n",
       "  777,\n",
       "  547,\n",
       "  3360,\n",
       "  14109,\n",
       "  13,\n",
       "  3162,\n",
       "  468,\n",
       "  3066,\n",
       "  284,\n",
       "  736,\n",
       "  284,\n",
       "  10240,\n",
       "  7636,\n",
       "  2405,\n",
       "  11,\n",
       "  543,\n",
       "  318,\n",
       "  644,\n",
       "  484,\n",
       "  750,\n",
       "  3161,\n",
       "  284,\n",
       "  3648,\n",
       "  13,\n",
       "  383,\n",
       "  3580,\n",
       "  783,\n",
       "  318,\n",
       "  326,\n",
       "  262,\n",
       "  25092,\n",
       "  4606,\n",
       "  481,\n",
       "  3328,\n",
       "  7636,\n",
       "  3264,\n",
       "  290,\n",
       "  407,\n",
       "  35373,\n",
       "  13,\n",
       "  632,\n",
       "  338,\n",
       "  1593,\n",
       "  284,\n",
       "  3465,\n",
       "  326,\n",
       "  262,\n",
       "  5583,\n",
       "  10874,\n",
       "  286,\n",
       "  1866,\n",
       "  286,\n",
       "  1111,\n",
       "  4671,\n",
       "  290,\n",
       "  867,\n",
       "  4956,\n",
       "  389,\n",
       "  287,\n",
       "  2661,\n",
       "  286,\n",
       "  6249,\n",
       "  10890,\n",
       "  262,\n",
       "  440,\n",
       "  5222,\n",
       "  780,\n",
       "  511,\n",
       "  1866,\n",
       "  547,\n",
       "  28517,\n",
       "  655,\n",
       "  355,\n",
       "  1690,\n",
       "  13],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7c4fc",
   "metadata": {},
   "source": [
    "# 核心解密：`batched=True` 的魔法\n",
    "\n",
    "您看到的 `tokenized_eli5[\"train\"][0]` 确实只是**一个样本**（一个列表）。\n",
    "\n",
    "但是，当您调用 `.map(group_texts, batched=True)` 时，HuggingFace Datasets 库并不会一个一个地把样本传给函数，而是**一次性抓取一批样本**（默认是 1000 个）。\n",
    "\n",
    "**数据变形记：**\n",
    "1. **存储时**：一个个独立的样本。\n",
    "   - 样本 1: `[1, 2, 3]`\n",
    "   - 样本 2: `[4, 5]`\n",
    "2. **传入函数时 (`examples`)**：变成了一个**包含多个列表的大列表**。\n",
    "   - `examples['input_ids']` 变成了 `[[1, 2, 3], [4, 5], ...]` (包含 1000 个小列表)\n",
    "3. **`sum(..., [])`**：把这 1000 个小列表“压扁”拼接成一个超长列表。\n",
    "\n",
    "让我们写个小代码验证一下传入函数的到底是什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证：看看传入函数的 examples 到底长什么样\n",
    "def inspect_batch_structure(examples):\n",
    "    print(\"=\"*40)\n",
    "    print(f\"函数接收到的 input_ids 类型: {type(examples['input_ids'])}\")\n",
    "    print(f\"这是一个包含 {len(examples['input_ids'])} 个列表的大列表\")\n",
    "    print(f\"前3个列表的内容: {examples['input_ids'][:3]}\")\n",
    "    print(\"=\"*40)\n",
    "    return examples\n",
    "\n",
    "# 我们只取前5个样本模拟一下 batched=True 的过程\n",
    "print(\"开始模拟 map(batched=True)...\")\n",
    "dummy_dataset = tokenized_eli5.select(range(5))\n",
    "dummy_dataset.map(inspect_batch_structure, batched=True, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80cfcb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e39128ae6c443eaeaa809cdd8cface",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b63e6d756c48e3a6883c7e94230918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [464,\n",
       "  4452,\n",
       "  286,\n",
       "  15757,\n",
       "  25092,\n",
       "  318,\n",
       "  262,\n",
       "  4795,\n",
       "  1767,\n",
       "  2727,\n",
       "  287,\n",
       "  3648,\n",
       "  284,\n",
       "  9161,\n",
       "  7636,\n",
       "  286,\n",
       "  17063,\n",
       "  416,\n",
       "  10191,\n",
       "  706,\n",
       "  1811,\n",
       "  37388,\n",
       "  290,\n",
       "  9253,\n",
       "  28449,\n",
       "  1908,\n",
       "  1866,\n",
       "  284,\n",
       "  3770,\n",
       "  13,\n",
       "  18626,\n",
       "  262,\n",
       "  6763,\n",
       "  28194,\n",
       "  423,\n",
       "  3066,\n",
       "  262,\n",
       "  1266,\n",
       "  835,\n",
       "  284,\n",
       "  2652,\n",
       "  503,\n",
       "  286,\n",
       "  7356,\n",
       "  318,\n",
       "  284,\n",
       "  2046,\n",
       "  262,\n",
       "  1644,\n",
       "  5011,\n",
       "  357,\n",
       "  273,\n",
       "  379,\n",
       "  1551,\n",
       "  1011,\n",
       "  1497,\n",
       "  511,\n",
       "  5635,\n",
       "  737,\n",
       "  10289,\n",
       "  62,\n",
       "  15,\n",
       "  383,\n",
       "  440,\n",
       "  5222,\n",
       "  373,\n",
       "  4385,\n",
       "  284,\n",
       "  307,\n",
       "  4795,\n",
       "  13,\n",
       "  2893,\n",
       "  326,\n",
       "  743,\n",
       "  307,\n",
       "  2081,\n",
       "  484,\n",
       "  625,\n",
       "  4169,\n",
       "  1496,\n",
       "  511,\n",
       "  22303,\n",
       "  290,\n",
       "  1690,\n",
       "  14109,\n",
       "  7636,\n",
       "  357,\n",
       "  4758,\n",
       "  547,\n",
       "  925,\n",
       "  35373,\n",
       "  8,\n",
       "  772,\n",
       "  878,\n",
       "  597,\n",
       "  13242,\n",
       "  547,\n",
       "  4251,\n",
       "  13,\n",
       "  770,\n",
       "  550,\n",
       "  617,\n",
       "  19958,\n",
       "  6948,\n",
       "  329,\n",
       "  867,\n",
       "  10218,\n",
       "  661,\n",
       "  13,\n",
       "  1338,\n",
       "  16421,\n",
       "  14227,\n",
       "  714,\n",
       "  307,\n",
       "  925,\n",
       "  1231,\n",
       "  597,\n",
       "  5925,\n",
       "  3920,\n",
       "  290,\n",
       "  777,\n",
       "  547,\n",
       "  3360,\n",
       "  14109,\n",
       "  13,\n",
       "  3162,\n",
       "  468,\n",
       "  3066],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [464,\n",
       "  4452,\n",
       "  286,\n",
       "  15757,\n",
       "  25092,\n",
       "  318,\n",
       "  262,\n",
       "  4795,\n",
       "  1767,\n",
       "  2727,\n",
       "  287,\n",
       "  3648,\n",
       "  284,\n",
       "  9161,\n",
       "  7636,\n",
       "  286,\n",
       "  17063,\n",
       "  416,\n",
       "  10191,\n",
       "  706,\n",
       "  1811,\n",
       "  37388,\n",
       "  290,\n",
       "  9253,\n",
       "  28449,\n",
       "  1908,\n",
       "  1866,\n",
       "  284,\n",
       "  3770,\n",
       "  13,\n",
       "  18626,\n",
       "  262,\n",
       "  6763,\n",
       "  28194,\n",
       "  423,\n",
       "  3066,\n",
       "  262,\n",
       "  1266,\n",
       "  835,\n",
       "  284,\n",
       "  2652,\n",
       "  503,\n",
       "  286,\n",
       "  7356,\n",
       "  318,\n",
       "  284,\n",
       "  2046,\n",
       "  262,\n",
       "  1644,\n",
       "  5011,\n",
       "  357,\n",
       "  273,\n",
       "  379,\n",
       "  1551,\n",
       "  1011,\n",
       "  1497,\n",
       "  511,\n",
       "  5635,\n",
       "  737,\n",
       "  10289,\n",
       "  62,\n",
       "  15,\n",
       "  383,\n",
       "  440,\n",
       "  5222,\n",
       "  373,\n",
       "  4385,\n",
       "  284,\n",
       "  307,\n",
       "  4795,\n",
       "  13,\n",
       "  2893,\n",
       "  326,\n",
       "  743,\n",
       "  307,\n",
       "  2081,\n",
       "  484,\n",
       "  625,\n",
       "  4169,\n",
       "  1496,\n",
       "  511,\n",
       "  22303,\n",
       "  290,\n",
       "  1690,\n",
       "  14109,\n",
       "  7636,\n",
       "  357,\n",
       "  4758,\n",
       "  547,\n",
       "  925,\n",
       "  35373,\n",
       "  8,\n",
       "  772,\n",
       "  878,\n",
       "  597,\n",
       "  13242,\n",
       "  547,\n",
       "  4251,\n",
       "  13,\n",
       "  770,\n",
       "  550,\n",
       "  617,\n",
       "  19958,\n",
       "  6948,\n",
       "  329,\n",
       "  867,\n",
       "  10218,\n",
       "  661,\n",
       "  13,\n",
       "  1338,\n",
       "  16421,\n",
       "  14227,\n",
       "  714,\n",
       "  307,\n",
       "  925,\n",
       "  1231,\n",
       "  597,\n",
       "  5925,\n",
       "  3920,\n",
       "  290,\n",
       "  777,\n",
       "  547,\n",
       "  3360,\n",
       "  14109,\n",
       "  13,\n",
       "  3162,\n",
       "  468,\n",
       "  3066]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples, tokenizer, block_size):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4, fn_kwargs={\"tokenizer\": tokenizer, \"block_size\": block_size})\n",
    "lm_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d1be1",
   "metadata": {},
   "source": [
    "# `group_texts` 函数详解\n",
    "\n",
    "这个函数的作用是将多个短文本拼接起来，然后按固定的长度（`block_size`）切分。\n",
    "\n",
    "**举个例子：**\n",
    "假设 `block_size = 4`，我们有 3 个短句子：\n",
    "1. `[1, 2]` (长度2)\n",
    "2. `[3, 4, 5]` (长度3)\n",
    "3. `[6]` (长度1)\n",
    "\n",
    "**处理过程：**\n",
    "1. **拼接**：`[1, 2, 3, 4, 5, 6]` (总长6)\n",
    "2. **计算新长度**：`6 // 4 * 4 = 4` (丢弃余数)\n",
    "3. **切分**：`[1, 2, 3, 4]` (只剩1个样本，长度为4)\n",
    "   - 丢弃了 `[5, 6]`\n",
    "\n",
    "**为什么要这样做？**\n",
    "- 训练大模型时，通常需要固定长度的输入（例如 128 或 1024）。\n",
    "- 这样可以把短句子拼起来，不浪费计算资源（避免大量的 padding）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c72c6f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 原始数据: [[1, 2], [3, 4, 5], [6]]\n",
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "[[1, 2], [3, 4, 5], [6]]\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "2. 拼接后: [1, 2, 3, 4, 5, 6]\n",
      "3. 总长度: 6\n",
      "4. 截断后长度: 4 (丢弃了最后 2 个 token)\n",
      "5. 最终结果 (每个样本长度为4): [[1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "# 代码演示 group_texts 的逻辑\n",
    "# 假设我们有3个短句子，block_size设为4\n",
    "examples = {\n",
    "    \"input_ids\": [[1, 2], [3, 4, 5], [6]],\n",
    "    \"attention_mask\": [[1, 1], [1, 1, 1], [1]]\n",
    "}\n",
    "block_size = 4\n",
    "\n",
    "print(\"1. 原始数据:\", examples['input_ids'])\n",
    "print(examples.keys())\n",
    "print(examples['input_ids'])\n",
    "print(sum(examples['input_ids'], []))\n",
    "# 1. 拼接\n",
    "concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "print(f\"2. 拼接后: {concatenated['input_ids']}\")\n",
    "\n",
    "# 2. 计算总长度\n",
    "total_length = len(concatenated[\"input_ids\"])\n",
    "print(f\"3. 总长度: {total_length}\")\n",
    "\n",
    "# 3. 截断 (丢弃余数)\n",
    "if total_length >= block_size:\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "print(f\"4. 截断后长度: {total_length} (丢弃了最后 {len(concatenated['input_ids']) - total_length} 个 token)\")\n",
    "\n",
    "# 4. 切分\n",
    "result = {\n",
    "    k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "    for k, t in concatenated.items()\n",
    "}\n",
    "print(f\"5. 最终结果 (每个样本长度为{block_size}): {result['input_ids']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
